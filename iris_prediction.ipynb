{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdf1d7e-611c-4e96-bbd3-14755ec6d651",
   "metadata": {},
   "source": [
    "*reference: https://janakiev.com/blog/pytorch-iris/\n",
    "*reference: https://sofiadutta.github.io/datascience-ipynbs/pytorch/Image-Classification-using-PyTorch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "01cd4c56-8f66-40a7-8e5e-41c3309573c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6907b8ca-03de-4425-9fe8-52090caed879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 110.45it/s]\n",
      "100%|██████████| 80/80 [00:00<00:00, 117.86it/s]\n",
      "100%|██████████| 80/80 [00:00<00:00, 117.03it/s]\n",
      "100%|██████████| 80/80 [00:00<00:00, 117.41it/s]\n",
      "100%|██████████| 80/80 [00:00<00:00, 120.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9393939393939394\n",
      "Recall: 0.9487179487179488\n",
      "F1 Score: 0.9388888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "Y = iris['target']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "# which is importance for convergence of the neural network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data set into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "# # # Converting X and Y into tensors \n",
    "# X_train = Variable(torch.from_numpy(X_train)).float()\n",
    "# y_train = Variable(torch.from_numpy(y_train)).long()\n",
    "# X_test  = Variable(torch.from_numpy(X_test)).float()\n",
    "# y_test  = Variable(torch.from_numpy(y_test)).long()\n",
    "# X = Variable(torch.from_numpy(X)).long()\n",
    "\n",
    "\n",
    "# Model Structure \n",
    "class model_structure(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super(model_structure,self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim,30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30,3),\n",
    "            nn.ReLU(),\n",
    "            nn.Softmax(dim=1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.net(x)\n",
    "        return out \n",
    "    \n",
    "# Hyperparameters\n",
    "class Param(object):\n",
    "    def __init__(self,epoch,batch_size,learning_rate,k_fold):\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.k_fold = k_fold\n",
    "        \n",
    "args = Param(80,10,0.001,5)\n",
    "model = model_structure(X_train.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=args.learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model\n",
    "\n",
    "# Initialize variables for tracking best model\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "epoch_loss_list = []\n",
    "epoch_accuracy_list = []\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=args.k_fold, shuffle=True)\n",
    "\n",
    "for train_index, val_index in cv.split(X):\n",
    "    # test train split \n",
    "    # Split the data into training set and validation set for the current fold\n",
    "    X_train, X_test = X[train_index], X[val_index]\n",
    "    y_train, y_test = y[train_index], y[val_index]\n",
    "\n",
    "    # Convert the data to PyTorch tensors\n",
    "    X_train_tensor = torch.Tensor(X_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train)\n",
    "    X_val_tensor = torch.Tensor(X_test)\n",
    "    y_val_tensor = torch.LongTensor(y_test)\n",
    "    \n",
    "    # Create a PyTorch DataLoader for batch processing\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in tqdm.trange(args.epoch):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            # forward\n",
    "            y_pred = model(inputs)\n",
    "            loss = loss_fn(y_pred,labels)\n",
    "\n",
    "            # Back-propagation and Resetting the optimizer \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(y_pred,1)\n",
    "            epoch_correct += (predicted == labels).sum().item()\n",
    "            epoch_total += labels.size(0)\n",
    "\n",
    "            epoch_loss /= len(train_loader.dataset)\n",
    "            epoch_accuracy = epoch_correct / epoch_total\n",
    "\n",
    "            epoch_loss_list.append(epoch_loss)\n",
    "            epoch_accuracy_list.append(epoch_accuracy)\n",
    "\n",
    "            loss_list.append(epoch_loss_list)\n",
    "            accuracy_list.append(epoch_accuracy_list)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val_tensor)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Calculate accuracy for the current fold\n",
    "        accuracy = accuracy_score(y_test, predicted)\n",
    "        \n",
    "        # Check if current model has higher accuracy than the best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_model = model\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "# Convert the predictions and true labels to numpy arrays\n",
    "predicted_np = predicted.numpy()\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "# metrics \n",
    "\"\"\"\n",
    "By setting average='macro', the metrics are calculated for each class independently, and then averaged. \n",
    "This approach treats all classes equally and can be useful when you want to evaluate the overall performance of the model across all classes.\n",
    "\"\"\"\n",
    "accuracy = accuracy_score(y_test_np, predicted_np)\n",
    "precision = precision_score(y_test_np, predicted_np,average='macro',zero_division=0)\n",
    "recall = recall_score(y_test_np, predicted_np,average='macro')\n",
    "f1 = f1_score(y_test_np, predicted_np,average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "02f6a02d-44a1-4260-b144-2f7214a7684c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3ed407fd-c54d-455a-9a59-9d90efc1ff5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8b5998e0-c603-438b-a54d-7debe0c5ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), 'best-model-parameters.pt') # official recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ef6ea600-3f25-4c53-abaa-5669bae67eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_structure(X_train.shape[1])\n",
    "model.load_state_dict(torch.load('./best-model-parameters.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "dab3b330-78a6-4bd2-87fa-8ebe048a5cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      0.92      0.96        12\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "best_model.eval()\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = best_model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "classification_rep = classification_report(y_test, predicted,labels=[0, 1, 2])\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(classification_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
