{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a59a857-f557-4562-a11e-f38cd5338b4a",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c309e0-2488-4203-b284-54d40eb9be9d",
   "metadata": {},
   "source": [
    "Batch Size: In machine learning, the training process involves updating the model's parameters based on the gradients computed from a batch of training samples. The batch size determines the number of samples that are processed together before the model's parameters are updated.\n",
    "\n",
    "For example, with a dataset of 1000 samples and a batch size of 100, there would be a total of 10 iterations or updates of the model's parameters.\n",
    "\n",
    "Reason behind the need of batch size: \n",
    "* Mmeory Efficient: batch size smaller than the entire datast\n",
    "* Computational Efficiency: Batch processing can take advantage of parallelism in modern hardware, such as GPUs. By processing multiple samples simultaneously, the computations can be distributed across multiple cores or devices, leading to faster training times.\n",
    "* Parameters to be updated more frequently, letting the model to converge to the local minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3888de-c51c-4d7a-a66f-c43dce36f273",
   "metadata": {},
   "source": [
    "* A larger batch size = more stable gradient estimates but computationally more expensive\n",
    "* Smaller batch size = more frequent update of model parameters and potentiall converge faster but introduce more noise in the estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece02cc2-0e8e-4db5-9bd1-e8305f5cf1b6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10cf7b82-7b4d-40c1-ad56-a98a590f3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f14ca114-bf42-4efc-b512-88381ffc59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Framework\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.linear(x)\n",
    "        out = self.sigmoid(out) # probabilities\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8467e489-960a-4f5e-abc2-dcd2ec559f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.6180\n",
      "Epoch [20/100], Loss: 0.5844\n",
      "Epoch [30/100], Loss: 0.5715\n",
      "Epoch [40/100], Loss: 0.5654\n",
      "Epoch [50/100], Loss: 0.5616\n",
      "Epoch [60/100], Loss: 0.5588\n",
      "Epoch [70/100], Loss: 0.5562\n",
      "Epoch [80/100], Loss: 0.5538\n",
      "Epoch [90/100], Loss: 0.5515\n",
      "Epoch [100/100], Loss: 0.5492\n"
     ]
    }
   ],
   "source": [
    "# Sample dataset\n",
    "X = torch.tensor([[1.0, 2.0], [2.0, 3.0], [3.0, 4.0], [4.0, 5.0]])\n",
    "Y = torch.tensor([[0.0], [0.0], [1.0], [1.0]])\n",
    "\n",
    "# Model hyperparameters\n",
    "class Params(object):\n",
    "    def __init__(self,input_size,learning_rate,epochs, threshold):\n",
    "        self.input_size = input_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.threshold = threshold\n",
    "        \n",
    "args = Params(2,0.01,100,0.7)\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(args.input_size)\n",
    "\n",
    "\n",
    "# Define Loss Function and Optimizer \n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=args.learning_rate)\n",
    "\n",
    "# Training_loop\n",
    "for e in range(args.epochs):\n",
    "    # forward pass\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "    \n",
    "    # Backword and optimization \n",
    "    \n",
    "    \"\"\" \n",
    "     In PyTorch, when performing backpropagation to compute the gradients of the model's parameters, \n",
    "     it is necessary to zero out the gradients from the previous iteration. \n",
    "     This is because PyTorch accumulates gradients by default, so if we don't reset the gradients, \n",
    "     they would accumulate and interfere with subsequent parameter updates.\n",
    "    \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    loss.backward()\n",
    "    \"\"\"\n",
    "    Computes the gradients of the loss function with respect to all the tensors that require gradients in the computational graph. \n",
    "    It essentially performs automatic differentiation and accumulates the gradients in the respective parameters of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    \"\"\"\n",
    "    Applies the computed gradients to the model's parameters using the specified optimization algorithm (e.g., SGD, Adam). \n",
    "    It adjusts the parameters in the direction that reduces the loss, allowing the model to learn from the training data.\n",
    "    \"\"\"\n",
    "    \n",
    "     # Print the progress\n",
    "    if (e + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{e+1}/{args.epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a428918-64fa-47ba-a77e-78773e016986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probability: 0.8169\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_input = torch.tensor([[5.0, 6.0]])\n",
    "predicted = model(test_input)\n",
    "print(f\"Predicted probability: {predicted.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab916695-6460-4fce-b989-f40b8fd77a0e",
   "metadata": {},
   "source": [
    "By default, the threshold is commonly set to 0.5, but you can adjust it according to your specific needs and the trade-off between precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c17770-36dd-4174-99a3-84c788b9f048",
   "metadata": {},
   "source": [
    "#### Changing the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66de605f-0f60-424a-a093-9c72b6f74c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming `outputs` contains the predicted probabilities\n",
    "# args.threshold = 0.7  # Set a new threshold value\n",
    "(predicted >= args.threshold).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9d831-ec76-49ba-8404-5b9b182360a2",
   "metadata": {},
   "source": [
    "A higher threshold tends to increase precision (reducing false positives), but it may lead to lower recall (missing some true positives). Conversely, a lower threshold increases recall (capturing more true positives) but may reduce precision (increasing false positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcc652d9-0fcb-4013-8746-54231896e734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4770312 ],\n",
       "       [0.57564396],\n",
       "       [0.6685808 ],\n",
       "       [0.7500033 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted Probabilities\n",
    "model(X).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b81eb-5e65-4631-89ca-c9385a785157",
   "metadata": {},
   "source": [
    "#### Predicted Proabilities with Blackbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbadd052-516f-46d9-a59b-087751c3f288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc01e5d2ad54040a2e9d47296c6ae50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce957eb8adec4a47832129c85e337d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.09291041176766157, 1: 0.001433192752301693}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[0, 1], [0, 1], [1, 0], [1, 0]], [[1, 0], [1, 0], [0, 1], [0, 1]]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#community\n",
    "from interpret.ext.blackbox import KernelExplainer\n",
    "from interpret.ext.blackbox import TabularExplainer\n",
    "\n",
    "X_np = X.numpy()\n",
    "\n",
    "# Use the blackbox explainer to explain the model's predictions\n",
    "\n",
    "explainer = KernelExplainer(\n",
    "        model,\n",
    "        initialization_examples =  X_np,\n",
    "        classes = [0,1],\n",
    "        # features = X_train.columns.tolist(),\n",
    "        model_task='classification')  \n",
    "\n",
    "global_explanation = explainer.explain_global(X_np)\n",
    "local_explanation = explainer.explain_local(X_np)\n",
    "\n",
    "# Print the feature importance values\n",
    "print(global_explanation.get_feature_importance_dict())\n",
    "sorted_local_importance_names = local_explanation.get_ranked_local_names()\n",
    "sorted_local_importance_values = local_explanation.get_ranked_local_values()\n",
    "sorted_local_importance_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d82db3ef-bcb2-430d-9220-79097cfe4ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [2., 3.],\n",
       "       [3., 4.],\n",
       "       [4., 5.]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5e1c65-4371-4205-9f2f-4ca67041c1a0",
   "metadata": {},
   "source": [
    "Reference: https://learn.microsoft.com/en-us/azure/machine-learning/v1/how-to-machine-learning-interpretability-aml?view=azureml-api-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf623e7-e6b1-4246-aff9-672be45ec0d8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e6ee5-a4fc-464d-864a-a9dfb2a1f885",
   "metadata": {},
   "source": [
    "Local Importance: Local importance refers to the interpretability of a model's predictions for a specific instance or observation in the dataset. It aims to explain why a particular prediction was made by highlighting the features or factors that influenced the model's decision for that specific instance.\n",
    "\n",
    "Local interpretability methods provide insights into the importance or contribution of individual features for a particular prediction. These methods often involve examining feature attributions, such as the magnitude and direction of feature contributions or feature importance scores for a specific instance.\n",
    "\n",
    "Examples of local interpretability methods include LIME (Local Interpretable Model-Agnostic Explanations), SHAP (SHapley Additive exPlanations), or feature importance techniques like permutation importance or partial dependence plots.\n",
    "\n",
    "Local importance helps provide a detailed understanding of the model's behavior for specific instances and can be valuable for debugging, error analysis, and gaining insights into individual predictions.\n",
    "\n",
    "\n",
    "*** \n",
    "Global Importance: Global importance, on the other hand, focuses on understanding the overall behavior of the model and the relative importance of features across the entire dataset. It aims to provide a broader perspective on the model's performance and feature relevance by considering the aggregate impact of features on the model's predictions.\n",
    "\n",
    "Global interpretability methods analyze the model as a whole and examine the general patterns and trends in feature importance across the dataset. They aim to identify the most influential features or factors for the model's predictions on average.\n",
    "\n",
    "These methods typically provide feature importance rankings or metrics that indicate the relative contribution of each feature to the model's predictions. They can help identify the most influential features, detect biases, or reveal the overall patterns captured by the model.\n",
    "\n",
    "Global importance techniques include global feature importance measures like permutation feature importance, mean decrease impurity, or gain in decision trees, as well as model-agnostic methods like feature importance derived from Shapley values or coefficients in linear models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
